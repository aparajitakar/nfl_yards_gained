{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aparajitakar/nfl_yards_gained/blob/main/Combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0owyKlaNlag"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wasVMgxqNrEH",
        "outputId": "d4be6632-4628-477e-ade7-b18870b2deee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGLy_gTJNvpG",
        "outputId": "755224bf-d885-42de-cad9-ca3d34f2713d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/CSCI 5523 Project/dev/csv/\n",
            "/content/gdrive/Shareddrives/CSCI 5523 Project/dev/csv/train.csv\n",
            "/content/gdrive/Shareddrives/CSCI 5523 Project/dev/csv/test.csv\n"
          ]
        }
      ],
      "source": [
        "main_dir = '/content/gdrive/Shareddrives/CSCI 5523 Project/dev/csv/'\n",
        "print(main_dir)\n",
        "\n",
        "# Pre-trained model directory\n",
        "train_data_dir = main_dir + 'train.csv'\n",
        "test_data_dir = main_dir + 'test.csv'\n",
        "print(train_data_dir)\n",
        "print(test_data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdr632BvNyNH"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_data_dir, low_memory=False)\n",
        "test_df = pd.read_csv(test_data_dir, low_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmNJZ_4XScCg"
      },
      "source": [
        "## Transform Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8hB3gZZTGa3"
      },
      "outputs": [],
      "source": [
        "median_humidity = train_df[\"Humidity\"].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iYPfRvNMJBd"
      },
      "outputs": [],
      "source": [
        "def clean_wind_directions(val):\n",
        "    if not isinstance(val, str):\n",
        "        return np.nan\n",
        "    aliases = [['^South$', '^s$', '^From S$', '^Southerly$'],\n",
        "                ['^West$', '^From W$', '^from W$'],\n",
        "                ['^North$'],\n",
        "                ['^East$', '^EAST$'],\n",
        "                ['^Southwest$', '^SouthWest$', '^South west$', '^From SW$'],\n",
        "                ['^Northwest$'],\n",
        "                ['^Northeast$', '^From NE$', '^NorthEast$', '^North East$'],\n",
        "                ['^Southeast$'],\n",
        "                ['^South-Southwest$', '^From SSW$', '^South Southwest$', '^S-SW$'],\n",
        "                ['^West-Southwest$', '^W-SW$', '^From WSW$'],\n",
        "                ['^West Northwest$', '^W-NW$'],\n",
        "                ['^North/Northwest$', '^From NNW$'],\n",
        "                ['^N-NE$', '^From NNE$'], \n",
        "                ['^East North East$', '^East NE$'],\n",
        "                ['^East Southeast$', '^From ESE$'],\n",
        "                ['^South, Southeast$', '^South Southeast$', '^From SSE$']]\n",
        "    actuals = ['S', 'W', 'N', 'E', 'SW', 'NW', 'NE', 'SE', 'SSW', 'WSW', 'WNW', 'NNW', 'NNE', 'ENE', 'ESE', 'SSE']\n",
        "    \n",
        "    for i in range(len(aliases)):\n",
        "        pattern = '|'.join(aliases[i])\n",
        "        if re.match(pattern, val):\n",
        "            return actuals[i]\n",
        "    return val\n",
        "\n",
        "def clean_turf(val):\n",
        "    turf_aliases = [['^Grass$', '^Natural Grass$', '^Natural grass$', '^Naturall Grass$', '^natural grass$', '^grass$', '^Natural$'],\n",
        "                ['^FieldTurf$', '^Field Turf$', '^FieldTurf360$', '^FieldTurf 360$', '^Field turf$', '^UBU Speed Series-S5-M$', '^UBU-Speed Series-S5-M$', '^UBU Sports Speed S5-M$', '^Twenty Four/Seven Turf$', '^Artifical$', '^A-Turf Titan$', '^SISGrass$', '^DD GrassMaster$', '^Twenty-Four/Seven Turf$']]\n",
        "    turf_actuals = ['Natural', 'Artificial']\n",
        "\n",
        "    for i in range(len(turf_aliases)):\n",
        "        pattern = '|'.join(turf_aliases[i])\n",
        "        if re.match(pattern, val):\n",
        "            return turf_actuals[i]\n",
        "    return val\n",
        "\n",
        "def new_orientation(angle, play_direction):\n",
        "    if play_direction == 0:\n",
        "        new_angle = 360.0 - angle\n",
        "        if new_angle == 360.0:\n",
        "            new_angle = 0.0\n",
        "        return new_angle\n",
        "    else:\n",
        "        return angle\n",
        "\n",
        "def StadiumType(val):\n",
        "    turf_aliases = [['^Outdoor$', '^Open$', '^Cloudy$', '^Bowl$', '^Outdoors$', '^OUTDOOR$', '^Oudoor$', '^Outddors$', '^Outside$', '^Ourdoor$', '^Outdor$', '^Heinz Field$'],\n",
        "                ['^Indoors$', '^Indoor$', '^Indoors$']]\n",
        "    turf_actuals = ['outdoor', 'indoor']\n",
        "\n",
        "    for i in range(len(turf_aliases)):\n",
        "        pattern = '|'.join(turf_aliases[i])\n",
        "        if re.match(pattern, val):\n",
        "            return turf_actuals[i]\n",
        "    return val\n",
        "\n",
        "def WindSpeed(X):\n",
        "    X.loc[:, 'WindSpeed_dc'] = X['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
        "    X.loc[:, 'WindSpeed_dc'] = X['WindSpeed_dc'].apply(lambda x: x.replace(', gusts to ', '').strip().split()[0] if not pd.isna(x) else x)\n",
        "    X.loc[:, 'WindSpeed_dc'] = X['WindSpeed_dc'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
        "    X.loc[:, 'WindSpeed_dc'].replace(\"calm\",0,inplace = True)\n",
        "    X.loc[:, 'WindSpeed_dc'] = X[\"WindSpeed_dc\"].apply(pd.to_numeric, errors='coerce').fillna(X[\"WindSpeed_dc\"].mode())\n",
        "    X.loc[:, 'WindSpeed_dc'].replace(np.nan, X[\"WindSpeed_dc\"].mean(),inplace = True)\n",
        "\n",
        "def strtosecs(txt):\n",
        "    txt = txt.split(':')\n",
        "    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
        "    return ans\n",
        "\n",
        "def getPositionCount(listVals, position):\n",
        "    count=0\n",
        "    for x in listVals:\n",
        "        if position in x:\n",
        "            count = int(re.findall(r'\\d+', x)[0])\n",
        "            break\n",
        "    return count\n",
        "\n",
        "def fix_weather(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\"&\", \"and\")\n",
        "  \n",
        "    for keyword in [\"coudy\", \"clouidy\"]:\n",
        "        x = x.replace(keyword, \"cloudy\")\n",
        "\n",
        "    x = x.replace(\"mostly \",\"\")\n",
        "    x = x.replace(\"party \", \"\")\n",
        "    x = x.replace(\"partly \",\"\")\n",
        "    x = x.replace(\"nan\", \"indoor\")\n",
        "\n",
        "    if \"rain\" in x or \"shower\" in x:\n",
        "        x = \"rainy\"\n",
        "    elif \"snow\" in x:\n",
        "        x = \"snow\"\n",
        "    elif \"cloud\" in x or \"overcast\" in x:\n",
        "        x = \"cloudy\"\n",
        "    elif \"sunny\" in x:\n",
        "        x = \"sunny\"\n",
        "    elif \"indoor\" in x or \"controlled\" in x or \"t: 51\" in x:\n",
        "        x = \"indoor\"\n",
        "    elif \"cold\" in x or \"cool\" in x:\n",
        "        x = \"cold\"\n",
        "    elif \"fair\" in x or \"clear\" in x:\n",
        "        x = \"clear\" \n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfBPDNGiO7gV"
      },
      "outputs": [],
      "source": [
        "def transform_data(og_data):\n",
        "    data = og_data.copy() # create copy so as to not touch original data\n",
        "    data.loc[:, 'WindDirection'] = data['WindDirection'].apply(clean_wind_directions)\n",
        "    data.loc[:, 'Turf'] = data['Turf'].apply(clean_turf)\n",
        "    data.loc[:, 'IsRusher'] = data['NflId'] == data['NflIdRusher']\n",
        "\n",
        "    data.loc[data.Season==2017,'S'] = data.loc[data.Season==2017,'S']*1.1320096503100632\n",
        "    data.loc[data.Season==2017,'A'] = data.loc[data.Season==2017,'A']*1.1210484653841495\n",
        "\n",
        "    data['PlayDirection'] = data['PlayDirection'].apply(lambda x: x.strip() == 'right')\n",
        "    data['X'] = data.apply(lambda row: row['X'] if row['PlayDirection'] else 120-row['X'], axis=1)\n",
        "    data['Orientation'] = data.apply(lambda row: new_orientation(row['Orientation'], row['PlayDirection']), axis=1)\n",
        "    data['Dir'] = data.apply(lambda row: new_orientation(row['Dir'], row['PlayDirection']), axis=1)\n",
        "\n",
        "    data[\"DP_DL\"] = data[\"DefensePersonnel\"].apply(lambda x: int(x.split()[0]))\n",
        "    data[\"DP_LB\"] = data[\"DefensePersonnel\"].apply(lambda x: int(x.split()[2]))\n",
        "    data[\"DP_DB\"] = data[\"DefensePersonnel\"].apply(lambda x: int(x.split()[4]))\n",
        "    data[\"DP_RB\"] = data[\"DefensePersonnel\"].apply(lambda x: 1 if \"RB\" in x else 0)\n",
        "    data[\"DP_OL\"] = data[\"DefensePersonnel\"].apply(lambda x: 1 if \"OL\" in x else 0)\n",
        "    data[\"Height_in_cms\"] = data[\"PlayerHeight\"].apply(lambda x:(int(x.split(\"-\")[0])*12 + int(x.split(\"-\")[1]))*2.54)\n",
        "\n",
        "    data['StadiumType'].fillna(value= \"outdoor\", inplace=True)\n",
        "    data[\"StadiumType\"] = data[\"StadiumType\"].apply(StadiumType)\n",
        "    data[\"StadiumType\"] = data[\"StadiumType\"].apply(lambda x: x.lower())\n",
        "    data[\"StadiumType\"] = data[\"StadiumType\"].apply(lambda x: \"outdoor\" if \"closed\" in x else x)\n",
        "    data[\"StadiumType\"] = data[\"StadiumType\"].apply(lambda x: \"indoor\" if \"open\" in x else x)\n",
        "    data[\"WindSpeed\"] = data[\"WindSpeed\"].astype(str)\n",
        "    data.loc[:, 'WindSpeed_dc'] = data['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
        "    data.loc[:, 'WindSpeed_dc'] = data['WindSpeed_dc'].apply(lambda x: x.replace(', gusts to ', '').strip().split()[0] if not pd.isna(x) else x)\n",
        "    data.loc[:, 'WindSpeed_dc'] = data['WindSpeed_dc'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
        "    data.loc[:, 'WindSpeed_dc'] = data['WindSpeed_dc'].replace(\"calm\",0)\n",
        "    data.loc[:, 'WindSpeed_dc'] = data[\"WindSpeed_dc\"].apply(pd.to_numeric, errors='coerce').fillna(data[\"WindSpeed_dc\"].mode())\n",
        "    data.loc[:, 'WindSpeed_dc'] = data['WindSpeed_dc'].replace(np.nan, data[\"WindSpeed_dc\"].mean())\n",
        "\n",
        "    data.loc[:, \"GameClock\"] = data[\"GameClock\"].apply(strtosecs)\n",
        "\n",
        "    # Setting up yard bins length\n",
        "    binsize = 2\n",
        "    aux_bins = []\n",
        "    aux_bins.append([-np.inf, -1])\n",
        "    aux_bins.append(list(range(0,11,binsize)))\n",
        "    aux_bins.append([15,20,np.inf])\n",
        "    # flatten list\n",
        "    bins_yds_flat = [item for sublist in aux_bins for item in sublist]\n",
        "    bins_yds_flat\n",
        "    data[\"YardBins\"] = pd.cut(data[\"Yards\"], bins_yds_flat)\n",
        "\n",
        "    data[\"HumidityNoNull\"] = data[\"Humidity\"].copy()\n",
        "    data.loc[:, \"HumidityNoNull\"] = data[\"HumidityNoNull\"].replace(np.nan, median_humidity)\n",
        "\n",
        "    data.FieldPosition.fillna('MFL', inplace=True)\n",
        "    df_players = pd.DataFrame({'OffensePersonnel' : []})\n",
        "    df_players['OffensePersonnel'] = data['OffensePersonnel'].str.replace('\\d+', '')\n",
        "    df_players = df_players['OffensePersonnel'].str.split(',', expand=True)\n",
        "    unique_player_positions = []\n",
        "    unique_player_positions.append(df_players[0].unique().tolist())\n",
        "    unique_player_positions.append(df_players[1].unique().tolist())\n",
        "    unique_player_positions.append(df_players[2].unique().tolist())\n",
        "    unique_player_positions.append(df_players[3].unique().tolist())\n",
        "    unique_player_positions.append(df_players[4].unique().tolist())\n",
        "    data[\"OP_RB\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'RB'))\n",
        "    data[\"OP_OL\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'OL'))\n",
        "    data[\"OP_QB\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'QB'))\n",
        "    data[\"OP_TE\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'TE'))\n",
        "    data[\"OP_WR\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'WR'))\n",
        "    data[\"OP_DL\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'DL'))\n",
        "    data[\"OP_LB\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'LB'))\n",
        "    data[\"OP_DB\"] = data[\"OffensePersonnel\"].apply(lambda x: getPositionCount(x.split(','),'DB'))\n",
        "\n",
        "    data['PlayerBirthYear'] = data['PlayerBirthDate'].apply(lambda x : int(x.split(\"/\")[-1]))\n",
        "    data['Age'] = data[\"Season\"] - data['PlayerBirthYear']\n",
        "    data.loc[:, 'GameWeather'] = data[\"GameWeather\"].apply(fix_weather)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDvqMDAsMI9o"
      },
      "outputs": [],
      "source": [
        "train_data = transform_data(train_df)\n",
        "test_data = transform_data(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDj3mneKZVOs"
      },
      "outputs": [],
      "source": [
        "# drop columns now\n",
        "drop_cols = ['Unnamed: 0', 'unique_idx', 'NflId', 'NflIdRusher', 'JerseyNumber', 'Yards',\n",
        "             'PlayerHeight', 'PlayerBirthDate', 'PlayerCollegeName', 'WindSpeed', 'Humidity', 'PlayerBirthYear', 'TimeHandoff', 'TimeSnap']\n",
        "train_data.drop(drop_cols, axis=1, inplace=True)\n",
        "test_data.drop(drop_cols, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy-2Xc60ZN4S"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKuk7NwQ02WQ"
      },
      "outputs": [],
      "source": [
        "# # CLUSTERED Data -- uncomment if we want to use it instead of the regular dataset\n",
        "# train_data = pd.read_csv('/content/gdrive/Shareddrives/CSCI 5523 Project/dev/csv/merged/clustered_data_train.csv', low_memory=False)\n",
        "# test_data = pd.read_csv('/content/gdrive/Shareddrives/CSCI 5523 Project/dev/csv/merged/clustered_data_test.csv', low_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqilQ--fvuQ7"
      },
      "source": [
        "## Oversampling and Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEz7eSwhvqLn"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aXJIefvqdfX"
      },
      "outputs": [],
      "source": [
        "def sample(X_train, y_train, sampling_type = 'over'):\n",
        "  unique_labels = y_train.YardBins.unique()\n",
        "\n",
        "  if(sampling_type == 'over'):\n",
        "    number_of_rows = y_train.YardBins.value_counts().max()\n",
        "    return RandomOverSampler(sampling_strategy={y_label: number_of_rows for y_label in unique_labels}).fit_resample(X_train, y_train)\n",
        "  else:\n",
        "    number_of_rows = y_train.YardBins.value_counts().min()\n",
        "    return RandomUnderSampler(sampling_strategy={y_label: number_of_rows for y_label in unique_labels}).fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJOKFhxAa_vK"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2Fl-ydrcFg4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "4WBnN6CTMIxF",
        "outputId": "47baa0b3-dcbd-430b-d743-231dca60110f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "YardBins    \n",
              "(0.0, 2.0]      98887\n",
              "(2.0, 4.0]      88152\n",
              "(4.0, 6.0]      52140\n",
              "(-inf, -1.0]    43184\n",
              "(-1.0, 0.0]     38344\n",
              "(6.0, 8.0]      27158\n",
              "(10.0, 15.0]    20856\n",
              "(8.0, 10.0]     17072\n",
              "(20.0, inf]      9196\n",
              "(15.0, 20.0]     8337\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train\n",
        "X_train = train_data.dropna()\n",
        "y_train = X_train[[\"YardBins\"]].astype(str)\n",
        "X_train = X_train.drop([\"GameId\", \"PlayId\", \"YardBins\", \"DisplayName\"], axis = 1)\n",
        "X_train = pd.get_dummies(X_train)\n",
        "\n",
        "# Test\n",
        "X_test = test_data.dropna()\n",
        "y_test = X_test[[\"YardBins\"]].astype('str')\n",
        "X_test = X_test.drop([\"GameId\", \"PlayId\", \"YardBins\", \"DisplayName\"], axis = 1)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "\n",
        "X_test = X_test.reindex(columns = X_train.columns, fill_value=0) # to remove any new columns added in OHE of test\n",
        "\n",
        "# uncomment if we want to use over/undersampling\n",
        "# X_train, y_train = sample(X_train, y_train, 'under')\n",
        "display(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Fc85hnnjjI",
        "outputId": "b96e3938-9d17-4a45-9db5-9aa59aab9277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " (-1.0, 0.0]       0.11      0.07      0.08     16410\n",
            "(-inf, -1.0]       0.13      0.09      0.10     18260\n",
            "  (0.0, 2.0]       0.26      0.40      0.31     42590\n",
            "(10.0, 15.0]       0.06      0.03      0.04      8558\n",
            "(15.0, 20.0]       0.02      0.01      0.01      3454\n",
            "  (2.0, 4.0]       0.24      0.32      0.27     38717\n",
            " (20.0, inf]       0.03      0.01      0.02      4025\n",
            "  (4.0, 6.0]       0.15      0.12      0.13     21757\n",
            "  (6.0, 8.0]       0.06      0.03      0.04     11725\n",
            " (8.0, 10.0]       0.07      0.03      0.04      7546\n",
            "\n",
            "    accuracy                           0.21    173042\n",
            "   macro avg       0.11      0.11      0.11    173042\n",
            "weighted avg       0.17      0.21      0.18    173042\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define the model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# fit the model on the whole dataset\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LAorLbFfMuX"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHZ9k0r2gEvm"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oN_yvOfMIrY",
        "outputId": "0166421d-3532-4bef-cc73-1823060204ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " (-1.0, 0.0]       0.12      0.19      0.15     16410\n",
            "(-inf, -1.0]       0.12      0.17      0.14     18260\n",
            "  (0.0, 5.0]       0.56      0.35      0.43     94617\n",
            "(10.0, 15.0]       0.06      0.10      0.07      8558\n",
            "(15.0, 20.0]       0.02      0.05      0.03      3454\n",
            " (20.0, inf]       0.02      0.04      0.03      4025\n",
            " (5.0, 10.0]       0.16      0.20      0.18     27718\n",
            "\n",
            "    accuracy                           0.26    173042\n",
            "   macro avg       0.15      0.15      0.15    173042\n",
            "weighted avg       0.36      0.26      0.30    173042\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "X_train = train_data.dropna()\n",
        "y_train = X_train[[\"YardBins\"]].astype('str')\n",
        "X_train = X_train.drop([\"GameId\", \"PlayId\", \"YardBins\", \"DisplayName\", \"GameClock\", \"Dis\"], axis = 1)\n",
        "X_train = pd.get_dummies(X_train)\n",
        "\n",
        "# Test\n",
        "X_test = test_data.dropna()\n",
        "y_test = X_test[[\"YardBins\"]].astype('str')\n",
        "X_test = X_test.drop([\"GameId\", \"PlayId\", \"YardBins\", \"DisplayName\", \"GameClock\", \"Dis\"], axis = 1)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "\n",
        "X_test = X_test.reindex(columns = X_train.columns, fill_value=0) # to remove any new columns added in OHE of test\n",
        "\n",
        "X_train, y_train = sample(X_train, y_train, 'under')\n",
        "\n",
        "#Decision Tree \n",
        "max_depth = 200\n",
        "model = tree.DecisionTreeClassifier(random_state = 1, max_depth = max_depth)\n",
        "#model = RandomForestClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# target_names = [\"Class 1\", \"Class 2\",\"Class 3\", \"Class 4\", \"Class 5\", \"Class 6\", \"Class 7\",\"Class 8\",\"Class 9\", \"Class 10\"]\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP8FGlUkgRG9"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAkaffiKgmGb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uttCZAxMIl0",
        "outputId": "79ac8a4a-ff63-4e65-a436-867b093a2db0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.13750418973428416\n"
          ]
        }
      ],
      "source": [
        "#Logistic Regression \n",
        "\n",
        "logit = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter = 800)\n",
        "logit.fit(X_train,y_train)\n",
        "y_pred = logit.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-eJEx2TqNnn"
      },
      "source": [
        "## Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IKiXZB7qUoK"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epTLa_fdqP2S",
        "outputId": "a7b20bff-2824-4eb1-d470-953e9bb31434"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0384762080882098\n"
          ]
        }
      ],
      "source": [
        "#Naive Bayes \n",
        "\n",
        "Nb = GaussianNB()\n",
        "Nb.fit(X_train,y_train)\n",
        "pred = Nb.predict(X_test)\n",
        "print(accuracy_score(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "voVCRKMhp9Ru",
        "outputId": "7500831d-958f-4322-8f20-6f906daa7ccc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "YardBins    \n",
              "(9.0, 15.0]     8337\n",
              "(6.0, 9.0]      8337\n",
              "(3.0, 6.0]      8337\n",
              "(20.0, inf]     8337\n",
              "(15.0, 20.0]    8337\n",
              "(0.0, 3.0]      8337\n",
              "(-inf, -1.0]    8337\n",
              "(-1.0, 0.0]     8337\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnGWiljGhfKV"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwiRRqypMIfx"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3PNC4uRMIaL",
        "outputId": "7296bcdb-7a43-47e8-f616-12f6b36e216a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "clf = svm.SVC(kernel='rbf',gamma='scale') ## 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "train_accuracy = clf.score(X_train, y_train)\n",
        "print('Train Accuracy %.3f'%(train_accuracy))\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRE5il_hsq-z"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For XGBoost, we do One-Hot Encoding for all categorical features and combine 22 rows into a single row. "
      ],
      "metadata": {
        "id": "DPBIZbUfaDSY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcVdqbqcvDNX"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMXtYoWfvH5C"
      },
      "outputs": [],
      "source": [
        "rusher_X_train = train_data[train_data['IsRusher'] == True]\n",
        "rusher_X_test = test_data[test_data['IsRusher'] == True]\n",
        "y_train = rusher_X_train['YardBins']\n",
        "y_test = rusher_X_test['YardBins']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop bins from train and test\n",
        "X_train = train_data.drop(\"YardBins\", axis=1)\n",
        "X_test = test_data.drop(\"YardBins\", axis=1)"
      ],
      "metadata": {
        "id": "3qlQxqbqd0Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLOHwQXbsp-v"
      },
      "outputs": [],
      "source": [
        "def combine_rows(X):\n",
        "    unused_columns = [\"GameId\",\"PlayId\",\"Team\", \"index\", \" \tUnnamed: 0\"]\n",
        "    unique_columns = [\"X\", \"Y\", \"S\", \"A\", \"Dis\", \"Orientation\", \"Dir\", \"PlayerWeight\", \"Height_in_cms\"]\n",
        "    training_cols = []\n",
        "    for c in X.columns:\n",
        "        if c not in unique_columns + unused_columns:\n",
        "            training_cols.append(c)\n",
        "    for c in unique_columns:\n",
        "        for i in range(22):\n",
        "            training_cols.append(c+str(i))\n",
        "\n",
        "    training_data=np.zeros((X.shape[0]//22,len(training_cols)))\n",
        "    for i in range(0,X.shape[0],22):#for all plays\n",
        "        count=0\n",
        "        for c in training_cols:\n",
        "            if c in X: #not in unique_columns and not in unused_columns\n",
        "                training_data[i//22][count] = X[c][i]\n",
        "                count+=1\n",
        "        for c in unique_columns:\n",
        "            for j in range(22):\n",
        "                training_data[i//22][count] = X[c][i+j]\n",
        "                count+=1\n",
        "    X = pd.DataFrame(data=training_data, columns=training_cols)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CcW6IisMIRo"
      },
      "outputs": [],
      "source": [
        "X_train = pd.get_dummies(X_train)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "X_test = X_test.reindex(columns = X_train.columns, fill_value=0) # to remove any new columns added in OHE of test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efa3ox6Hx8t5"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqJV1vqIvPVN"
      },
      "outputs": [],
      "source": [
        "combined_X_train = combine_rows(X_train)\n",
        "combined_X_test = combine_rows(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMeDWTxg0-ZB"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reset_index(drop=True).astype(str)\n",
        "y_test = y_test.reset_index(drop=True).astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0eiUaU96ZWW"
      },
      "outputs": [],
      "source": [
        "# maintaining order when we pass the array as an XGBoost array\n",
        "mapping = {'(-inf, -1.0]': 0, '(-1.0, 0.0]': 1, '(0.0, 2.0]': 2, '(2.0, 4.0]': 3, '(4.0, 6.0]': 4, '(6.0, 8.0]': 5, '(8.0, 10.0]': 6, '(10.0, 15.0]': 7, '(15.0, 20.0]': 8, '(20.0, inf]': 9}\n",
        "y_train_enc = np.array(y_train.replace(mapping))\n",
        "y_test_enc = np.array(y_test.replace(mapping))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "673duNiMvaAw"
      },
      "outputs": [],
      "source": [
        "kfold = 5\n",
        "skf = StratifiedKFold(n_splits=kfold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StrFdwr8vass"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'booster': 'dart',\n",
        "    'max_depth': 10,\n",
        "    'objective': 'multi:softmax',  # error evaluation for multiclass training\n",
        "    'num_class': 10,\n",
        "    'eval_metric': 'mlogloss', \n",
        "    'nthread': 25,\n",
        "    'verbosity': 1,\n",
        "    'learning_rate': 0.1,\n",
        "    'min_child_weight': 2,\n",
        "    'rate_drop': 0.3,\n",
        "    'skip_drop': 0.3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovJgY5oMvckm",
        "outputId": "b3699406-ca46-4342-9392-4c30516e78ea"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Fold 1/5]\n",
            "[0]\ttrain-mlogloss:2.21711\tvalid-mlogloss:2.2699\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[100]\ttrain-mlogloss:1.36816\tvalid-mlogloss:2.05772\n",
            "Stopping. Best iteration:\n",
            "[139]\ttrain-mlogloss:1.15438\tvalid-mlogloss:2.01942\n",
            "\n",
            "[Fold 1/5 Prediciton:]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.05      0.08       991\n",
            "           1       0.22      0.02      0.04       860\n",
            "           2       0.26      0.58      0.36      2297\n",
            "           3       0.24      0.41      0.31      2089\n",
            "           4       0.14      0.04      0.07      1172\n",
            "           5       0.09      0.00      0.00       633\n",
            "           6       0.33      0.00      0.00       409\n",
            "           7       0.25      0.00      0.01       456\n",
            "           8       0.00      0.00      0.00       188\n",
            "           9       0.00      0.00      0.00       208\n",
            "\n",
            "    accuracy                           0.25      9303\n",
            "   macro avg       0.17      0.11      0.09      9303\n",
            "weighted avg       0.21      0.25      0.18      9303\n",
            "\n",
            "[Fold 2/5]\n",
            "[0]\ttrain-mlogloss:2.21824\tvalid-mlogloss:2.27222\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[100]\ttrain-mlogloss:1.3721\tvalid-mlogloss:2.09901\n",
            "[200]\ttrain-mlogloss:1.00943\tvalid-mlogloss:2.12435\n",
            "Stopping. Best iteration:\n",
            "[183]\ttrain-mlogloss:0.676472\tvalid-mlogloss:2.07513\n",
            "\n",
            "[Fold 2/5 Prediciton:]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.06      0.09       991\n",
            "           1       0.23      0.02      0.04       860\n",
            "           2       0.26      0.55      0.35      2297\n",
            "           3       0.24      0.42      0.30      2089\n",
            "           4       0.15      0.04      0.07      1172\n",
            "           5       0.29      0.00      0.01       633\n",
            "           6       0.00      0.00      0.00       409\n",
            "           7       0.27      0.01      0.01       456\n",
            "           8       0.00      0.00      0.00       188\n",
            "           9       0.00      0.00      0.00       208\n",
            "\n",
            "    accuracy                           0.24      9303\n",
            "   macro avg       0.16      0.11      0.09      9303\n",
            "weighted avg       0.21      0.24      0.18      9303\n",
            "\n",
            "[Fold 3/5]\n",
            "[0]\ttrain-mlogloss:2.22047\tvalid-mlogloss:2.27069\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[100]\ttrain-mlogloss:1.36438\tvalid-mlogloss:2.07098\n",
            "Stopping. Best iteration:\n",
            "[96]\ttrain-mlogloss:1.29017\tvalid-mlogloss:2.04287\n",
            "\n",
            "[Fold 3/5 Prediciton:]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.06      0.09       991\n",
            "           1       0.23      0.04      0.06       860\n",
            "           2       0.26      0.56      0.35      2297\n",
            "           3       0.24      0.39      0.30      2089\n",
            "           4       0.14      0.05      0.07      1172\n",
            "           5       0.15      0.00      0.01       633\n",
            "           6       0.22      0.00      0.01       409\n",
            "           7       0.21      0.01      0.02       456\n",
            "           8       0.50      0.01      0.01       188\n",
            "           9       0.00      0.00      0.00       208\n",
            "\n",
            "    accuracy                           0.24      9303\n",
            "   macro avg       0.21      0.11      0.09      9303\n",
            "weighted avg       0.22      0.24      0.18      9303\n",
            "\n",
            "[Fold 4/5]\n",
            "[0]\ttrain-mlogloss:2.21649\tvalid-mlogloss:2.267\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[100]\ttrain-mlogloss:1.35102\tvalid-mlogloss:2.05917\n",
            "Stopping. Best iteration:\n",
            "[106]\ttrain-mlogloss:1.2432\tvalid-mlogloss:2.02144\n",
            "\n",
            "[Fold 4/5 Prediciton:]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.05      0.08       991\n",
            "           1       0.21      0.03      0.05       860\n",
            "           2       0.25      0.56      0.35      2297\n",
            "           3       0.25      0.41      0.31      2089\n",
            "           4       0.14      0.05      0.07      1172\n",
            "           5       0.00      0.00      0.00       633\n",
            "           6       0.17      0.00      0.00       409\n",
            "           7       0.11      0.00      0.01       456\n",
            "           8       0.00      0.00      0.00       188\n",
            "           9       0.00      0.00      0.00       208\n",
            "\n",
            "    accuracy                           0.24      9303\n",
            "   macro avg       0.13      0.11      0.09      9303\n",
            "weighted avg       0.19      0.24      0.18      9303\n",
            "\n",
            "[Fold 5/5]\n",
            "[0]\ttrain-mlogloss:2.21158\tvalid-mlogloss:2.26887\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n"
          ]
        }
      ],
      "source": [
        "for i, (train_index, test_index) in enumerate(skf.split(combined_X_train, y_train_enc)):\n",
        "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
        "    X_train1, X_valid = combined_X_train.values[train_index], combined_X_train.values[test_index]\n",
        "    y_train1, y_valid = y_train_enc[train_index], y_train_enc[test_index]\n",
        "    # Convert data into XGBoost format\n",
        "    d_train = xgb.DMatrix(X_train1, y_train1)\n",
        "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
        "    d_test = xgb.DMatrix(combined_X_test.values)\n",
        "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "    # Train the model. We pass in a max of 500 rounds (with early stopping after 50)\n",
        "    mdl = xgb.train(params, d_train, 500, watchlist, early_stopping_rounds=50, verbose_eval=100)\n",
        "\n",
        "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
        "    # Predict on our test data\n",
        "    p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)\n",
        "    print(classification_report(y_test_enc, p_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Combined.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}